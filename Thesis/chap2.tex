%% \documentclass[authoryear,final,5p,twocolumn]{elsarticle}
%% \usepackage{amssymb}
%% \journal{Journal of Environmental Modelling and Software}
%% \begin{document}
%% \begin{frontmatter}
%% \title{Increasing model efficiency by dynamically changing model representations}
%% \author{Randall Gray\corref{cor1}}
%% \cortext[cor1]{Corresponding author}
%% \address{CSIRO Division of Marine and Atmospheric Research}
%% \ead{Randall.Gray@csiro.au}
%% \author{Simon Wotherspoon}
%% \address{University of Tasmania}
%% \ead{Simon.Wotherspoon@utas.edu.au}
%% \begin{abstract}
%%   There are a number of strategies to deal with modelling large complex
%%   systems such as large marine ecosystems. These systems are often comprised
%%   of many submodels, each contributing to the overall trajectory of the
%%   system. The balance between the acceptable modelling error and the run-time
%%   often dictates the form of these submodels. There may be scope to improve
%%   the position of this balance point in both regards by structuring models so
%%   that submodels may change their algorithmic representation and state space
%%   in response to their local state and the state of the model as a whole.
  
%%   This paper uses an example system consisting of a single population of
%%   animals which periodically encounters a diffuse contaminant in a localised
%%   region as an example of such a system, and discusses the key issues that
%%   arise from the approach.
%% \end{abstract}
%% \end{frontmatter}

\chapter{Increasing model efficiency by dynamically changing model representations}

\begin{center}
    Randall Gray\footnote{
     {Published in \emph{Environmental Modelling and Software}, 2012}\\
       Corresponding author:
      \texttt{Randall.Gray@limnal.net} (Randall Gray),\\
      \texttt{Simon.Wotherspoon@utas.edu.au} (Simon Wotherspoon)
    }

    \emph{CSIRO Division of Marine and Atmospheric Research}

    Simon Wotherspoon 

    \emph{University of Tasmania}
\end{center}

\rule{\textwidth}{2pt}

\begin{description}
  \item[ ]
    \textbf{Abstract}

    There are a number of strategies to deal with modelling large complex
    systems such as large marine ecosystems. These systems are often comprised
    of many submodels, each contributing to the overall trajectory of the
    system. The balance between the acceptable modelling error and the run-time
    often dictates the form of these submodels. There may be scope to improve
    the position of this balance point in both regards by structuring models so
    that submodels may change their algorithmic representation and state space
    in response to their local state and the state of the model as a whole.
  
    This paper uses an example system consisting of a single population of
    animals which periodically encounters a diffuse contaminant in a localised
    region as an example of such a system, and discusses the key issues that
    arise from the approach.
\end{description}

\rule{\textwidth}{2pt}

\section{Introduction}\label{Intro}

There is a body of literature stretching back several decades which discusses
individual-based modelling as a useful alternative to classical models. Early
examples modelled forest canopy dynamics, notably JABOWA and its derivatives
(\citet{Botkin72:1}, \citet{Botkin72:2}). The number of significant papers and
books has steadily increased since the 1980s. These works describe the use of
individual-based models across a broad range of systems, and the relative
strengths and weaknesses of the approach (such as \citet{Huston88:1},
\citet{DeAngelis92:1} and \citet{Grimm05:1}). Classical models exploring
populations and ecological systems are usually associated with modelling the
dynamics of large groups and arguably appeared at the end of the eighteenth
century with Malthus's {\em{{\textbf{An Essay on the Principle of
Population}}}} (\citeyear{Malthus:1}). The properties of these models are well
understood and their state variables usually correspond to measurable
quantities. Often, they are much faster than individual-based counterparts,
and the analysis of model error may be much more straightforward. Classical
and individual-based approaches represent the ends of a spectrum of
aggregation in time, space and membership. Representations lying between these
extrema, such as described by \citet{Scheffer95:1}, capitalise on the
process-fidelity of an individual-based representation and gain some of the
computational efficiency of a more aggregated classical approach, but an
adaptive exploitation of the strengths of different representations is
possible and worth exploring.

Ecosystem models are becoming broader in scope (\citet{Rose10:1},
\citet{DeAngelis98:1}, \citet{Harvey03:1} \citet{Fulton04:1}, \citet{NWSJEMS:1},
\citet{Ningaloo:1}) and include more species with richer environments. The
environmental response to climate change has also made anthropogenic pressure
an important feature in many of these models. As this trend grows it seems
less likely that a single model drawn from any particular region of this
spectrum will be able to address all members and processes equally well.
Simulation models often embed their subject in an ``environment'' comprised of
primary data and other models and these components may occupy many places in
the spectrum of representations. The model's actual implementation may be
anything from a set of distinct models which are coupled together but retain
their independence, to a corpus of code with the submodels so integrated that
there is no real distinction between one ``model'' and the next.

The dynamics associated with biological and ecological systems can depend on
the distributions and states of individuals in ways which are not amenable to
equation-based modelling. The individual-based models described in
\citet{Farolfi2010}, and \citet{Almeida2010} deal with systems of this sort.
Versions of these models could be embedded in a common simulation environment
in order to address more complex problems which span traditional domain
boundaries, and such a model could address broader questions, such as how
mosquito control strategies may best adapt to evolving agricultural practices
and watershed conditions. \Citet{Thiele2010} describes an extension to NetLogo
which allows modellers to incorporate calls to R functions to aid in
configuring the model to meet desirable mathematical conditions, to provide
ongoing analysis, and to display the model's state through its run. This
interface between R and NetLogo could be extended to support incorporating
mathematical decision models written in R into the model's decision tree. The
fusion of these three elements would form a system capable of simulating
possible trajectories for the management of watersheds and human health in
ways which would not be possible with a traditional monolithic modelling
approach.

Models are including more functional groups and the interactions between
components are becoming more detailed. It is costly in terms of computational
load to address this increased demand for detail: individual-based models of
populations may be very good at capturing vulnerability to exceptional events,
but such simulations take a long time. Much of this time may be spent with the
model in a largely unchallenging or uninteresting part of its state-space.

This paper explores the technique of changing the representation of a
component of a model based on its location in its state-space. Modellers
already do this to some degree: time-steps or spatial resolutions are changed,
particular code paths may be by-passed to avoid pointless work, or additional
calculations might be performed to reduce the error when the state is changing
rapidly. These optimisations are largely optimisations of the
{\em{encoding}} of the model or submodels, rather than an actual change in
representation.

\Citet{Vincenot11:1} make a clear case for considering what the authors term
``hybrid-models.'' They present four reference cases which they use to
describe ways in which equation-based models and individual-based models might
be coupled to increase their utility. Their categories of hybrid-models are:
individual-based models interacting with a single system dynamics model,
system dynamics models embedded in individual-based models, individual-based
models interacting with a number of system dynamics models, and models in
which the representation swaps between individual-based and an equation-based
form. They argue that a hybrid approach may provide a means of increasing the
speed and accuracy of our models and \citet{Lyne94:1} and \citet{Gray06:1} have
demonstrated that large models of ecosystems can be modelled this way.
\citeauthor{Vincenot11:1} note that they found relatively few models which use both
individual-based and equation-based submodels, and they present no existing
models representing their fourth reference case. This final case, where models
swap from equation-based to individual-based, is briefly described in general
terms and is clearly intended to encompass models like the model of this
paper.

This ``mutating'' or ``switching'' approach to the problem of managing
complex simulations was developed using the experience from making several
large scale human-ecosystem interaction models (\citeauthor{Lyne94:1};
\citeauthor{Gray06:1}; and a current, larger study of Ningaloo coastal region
({\em{work in progress}})). In each of these studies a significant component
of the model focused on simulating the interaction between organisms and
contaminant plumes, though there is nothing that inherently limits the
techniques to these sorts of studies. \textbf{Citeauthor{Lyne94:1}} assessed the
potential of contaminants originating in industrial waste percolating through
the food chain into commercially exploited fish stocks. \citeauthor{Gray06:1}
developed a regional model to assess managment strategies for human activity
which interacts with the biological systems along the Northwest Shelf of
Australia.

Simulating contaminant interactions in an ecosystem is expensive in terms of
run-time and memory use. The models described by \citeauthor{Gray06:1} and
\citeauthor{Lyne94:1} include contaminant transport, uptake and depuration
modelling, with behavioural sensitivity to contaminants. In \citeauthor{Gray06:1},
the time taken to run a simulation with contaminants increased by roughly an
order of magnitude, and in both studies a large amount of time was spent in
regions where no interaction with contaminant plumes was possible.
\citet{Monte09:1} presents a lucid discussion of analytic {\em{contaminant
migration-population effects}} models. These models incorporate the movement
of populations and their internal distribution, the transport of contaminants
through the system via biotic and abiotic pathways, and the changes in
behaviour and population dynamics associated with contamination.
\Citeauthor{Monte09:1} discusses a method of coupling the equations which govern
contaminant dispersion with the equations for population dynamics and
migration. The technique depends on the equations of the location and the
dispersion of members of a population satisfying an independence condition
with respect to time and location which must hold. He states that the class of
systems where the ``movement of animals, the death and birthrates of
individuals in $\mathbf{x}$ [location] at instant $t$ [time] depend on
previously occupied positions'' is not generally amenable to the approach and
suggests that repeated simulations of many individuals is an appropriate way
of dealing with this situation.

It is unnecessary to run a complex model and carry the burden of maintaining
its state when a simple model may perform better. If representations are
switched appropriately, there is potential for improvements in run-time and
accuracy. We need to consider four basic questions to do this:
\begin{enumerate}
  \item What data need to persist across representations?\label{Q1}
  
  \item When should a model change representation?\label{Q2}
  
  \item How is the initial state for a new representation
  constructed?\label{Q3}
  
  \item How should the error associated with the loss of state information be
  managed?\label{Q4}
\end{enumerate}
The answer to these questions is specific to the set of submodels in question.
Before expending resources and effort on a large scale model there needs to be
a demonstration that the notion is worth pursuing, and some indication of how
it might be accomplished. The aim of this paper is to provide this
demonstration rather than to develop a comprehensive body of techniques
supporting the approach. Many systems may benefit from similar techniques;
obvious candidates are models of marginal populations, and the population
dynamics of animals with behaviour where short periods of time have a
significant influence on population levels (\citet{Wolff94:1} and
\citet{Elderd08:1}, for example).

\section{Overview: an {\em{ODD}} model description}\label{ODD}

The {\em{ODD}} protocol \citep{Grimm06:1} is used to describe the example
model. We discuss the issues associated with making such a system, strategies
and the reasons behind them in the Discussion section.

\subsection{Purpose}

This example model plays two roles. Its first is as an explicit demonstration,
and the second is as a tool to explore the larger subject of changing a
model's representation in response to its state. This example is overly
simple, but it shares a number of features with plausible models and the
analysis and development of the mutating model should be a reasonable template
for other systems.

The model simulates organisms moving along a simple migratory path which
intersects a region containing a field of fluctuating contamination (see
Figure \ref{Fig1}). This model exhibits fundamental attributes of larger
studies of pollutant/ecosystem interactions (\citeauthor{Lyne94:1} and
\citeauthor{Gray06:1}) and, while it is not intended to accurately represent any
particular system, it might loosely correspond to some body of water
influenced by contaminant loads associated with terrestrial runoff resulting
from intense rainfalls.

\begin{figure}[h]
  
  \caption{Snapshots of individuals' locations at 28 day intervals
  superimposed on the migratory path. The plume's contact domain is marked by
  a grey ellipse near the position of individuals at day 28, with the track of
  a single individual approaching it. The domain of a population is is
  circumscribed around the individuals at day 196 for comparison.}
\end{figure}\label{Fig1}



The test models are composed of one or more submodels which run within a
simple time-sharing system. Each submodel runs for a nominated period of time
and passes control to the next submodel, very much like tasks running in many
modern computer operating systems. In a {\em{mutating}} configuration, a
trial will have different models take turns representing components of the
system.

The population-based and individual-based submodels have been kept as similar
as practicable in order to minimise the sources of divergence.

\subsection{State variables and scales}

There are essentially three distinct submodels in the simulation: an
individual-based representation of the migrating group, population-based
representation of the group, and a contaminant uptake-depuration model. We can
think of the models which take the role of the group as candidates for filling
a {\em{niche}}\label{Niche}, which we can think of as the ``sub-model shaped
hole'' in the middle of the program. Because the individual-based and
population based models have fundamentally different spatial representations,
each of these models include mechanisms to evaluate their contact with a plume
as they move through their environment. The spatial domain of the whole model
system is a circular region with an arbitrary radius of somewhat more than
100km which encompasses both the area influenced by the contaminant source and
the annual migratory path of the organisms. The plume can be viewed as a
forcing function in the model and it has a maximum footprint area of
approximately $43 {km}^2$ which may be circular or elliptical and is
centered on a point of the migratory circle. Both the elliptic and circular
variants of the plume have the same area, and their intensities are adjusted
so that the integral of the contaminant concentration over the region is the
same.

The individual-based representation maintains a contaminant load associated
with contact with the plume, a location, a direction and the next time at
which it is scheduled to run. The population-based representation treats the
group as homogeneous with respect to all state variables other than the
contaminant load, and maintains only a record of its next time-to-run and an
indication of contaminant load in the population. In the straight
population-based representation, this is a single value, but in the mutating
system the submodel maintains a list of contaminant loads which correspond to
the non-zero loads of individuals. The plume model is deterministic with
respect to time and location and maintains no state variables.

\subsection{Process overview and scheduling}

Simulations were run with 90 minute timesteps for a period representing twelve
years. At each time-step, each instance of a submodel is rostered in a
priority queue sorted on the ``time-to-run'' state variable, and when it comes
to the top of the queue it executes.

Populations operate in a straightforward way: their path is deterministic,
exposure to contaminants is calculated, and the resulting values are fed
through the uptake-depuration equation. Individuals calculate their path (a
segment of a directed random walk which follows the path of migration) and
contact for the timestep and an apply the uptake-depuration equation. At the
end of a timestep in non-mutating configurations, data is accumulated for
output and each submodel reinserts itself in the priority queue. Otherwise, a
heuristic is used to choose an appropriate representation for the niche in
next timestep and that is inserted into the queue. Randomisation within a
time-step is unnecessary, since the individual's or the population's
contaminant updates are resolved for the contaminant contact across their
time-step and are not dependent on the state of any other agents.

\section{Design concepts}

The central reason for the model is the mutability of the representation of
the simulated organisms. Individuals and populations in the model are
profoundly simple: no real scope is present for any of the trait categories
mentioned in \citet{Grimm06:1}, apart from their interaction with the
contaminant plume, though this interaction is completely deterministic with
respect to their path through the plume. In place of these traits, we have the
basic heuristics associated with triggering a change from a population-based
representation to individuals and a corresponding heuristic which indicates
when an individual should join (or become) a population. The actual mechanism
which turns a population into individuals or its converse is not necessarily a
property of those models. Since the objective is to examine the impact of
changing model representation in a fairly narrow situation, no attempt is made
to optimise the submodels in the ``non-contact'' areas which constitute most
of the model domain.

\section{Details}

\subsection{Initialisation}

Individuals and populations initially begin with no contaminant load, and
individuals are positioned according to the two-dimensional normal
distribution which characterises the population's assumed distribution. When a
population mutates into an appropriate set of individuals, the individuals are
positioned in the same fashion (centered on the centre of the population) with
their corresponding contaminant loads either taken from the list of non-zero
contaminant loads maintained by the population or initialised to be zero
should the population's list fall short.

\subsection{Input\label{Circle-and-plume}}

Several characteristic features of the model are determined by the time and
location represented. The contaminant intensity (and hence extent) at any
point, $\mathbf{r},$ relative to the centroid of the plume,
$\mathbf{m}_{{plume}}$, at a time, $t$, by the equation
\[ I (t, \mathbf{r}) = \frac{1}{2} (1 + \cos (2 \pi t / p)) \exp (- \psi \phi ( \mathbf{r}, \mathbf{m}_{{plume}})) \]
where $p$ is the period of 34 days, $\psi = 0.05$ is a decay exponent. We take
$\phi$ to be a distance function, either $\phi ( \mathbf{a}, \mathbf{b}) = | \mathbf{a} - \mathbf{b} |$, for a circular plume, or
$\phi ( \mathbf{a}, \mathbf{b}) = \sqrt{ ( \mathbf{a} - \mathbf{b}) \cdot ( \sqrt[]{2}, \sqrt{1 / 2})}^{}$, for an elliptical plume. The effective radius of
the circular plume in the model is about 3.7\% of the circular migratory path
of the populations and individuals. The intensity of the elliptical plume is
adjusted by scalar multiplication so that the integral of $I$ for the two
plumes over their domain is the same.

The individual-based and population-based models follow a circular migratory
path about the origin. The path is traced annually and its location at any
given time follows the equation $\mathbf{l} \left( t \right) = 10^5 \left( \cos \left( 2 t \pi / 365.25 \right), \sin \left( 2 t \pi / 365.25\right) \right)$.

\subsection{Submodels}

\subsubsection{Individual-based representation}

Individuals follow a directed random walk around the migratory circle
described in the previous section. At each time-step the stride the individual
takes is calculated according to its proximity to the ``target'' on the
migratory path. There are a number of parameters associated with the movement
of the individuals presented in Table \ref{IBMovement}.

\begin{table}[h]
\begin{center}
  \caption{Parameters associated with individual movemement\label{IBMovement}}
  \begin{tabular}{ccc}
\hline  &  &   \cr
    Parameter & Value & Description \cr
\hline  &  &   \cr
    $\overline{V}$ & 4 & A ``variability'' parameter associated \cr
    &  & with a Poisson-like process \cr
    $q$ & 0.5 & A magnitude control parameter on \cr
    &  & directional change \cr
    $\mu_{\delta}$ & 1 day & Notional interval over which we \cr
    &  & calibrate individual's movement \cr
    $\mu$ & 20km & Indicates the radius which is likely \cr
    &  & in a period of $\mu_{\delta}$ \cr
    $s$ & 4ms$^{- 1}$ & nominal speed of the individuals  \cr
\hline  &  & 
  \end{tabular}
\end{center}
\end{table}

If we take $\delta$ to be the length of the current time step, and $v$ to be a
realisation of an event in a Poisson-like process with a mean of
$\overline{V}$, we can take
\[ Q = \left[ 1 - \exp \left( \frac{v}{\bar{V}} \log \left( 1 - q \right) \right) \right]  \]
to be a ``variation'' scalar which we use to evaluate an effective radial
speed,
\[ \nu_s = \left| - 1 + \sqrt{1 + 4 s Q^2 \frac{\delta}{\bar{V}}} \right| / 2 Q^2 . \]
Large values of $Q$ correspond to long stretches of time without a
change in direction, so we include $Q$ in the calculation of $\alpha$,
the partial change in the individual's direction vector, by setting it
to $\alpha = \pi {rnd} \left( - Q, Q \right)$. We can take their
effective displacement over the 90 minute interval to be determined by
a weighted sum of the normalised vector which joins them to their
``target'' location on the migratory path and a direction vector of
length $\nu_s$ which is deflected by $\alpha$.

\subsubsection{Population-based representation}

The population-based model assumes that a radially symmetric, normal
distribution of individuals is an appropriate representation. Trials using the
movement model of the individual-based model were run, and the positions of
individuals relative to their ``target'' on the migratory circle at each
time-step closely matched a 2D-normal distribution with a $\sigma^2 =
3136.25^2$. Using this value, we define the density of the population at the
point $\mathbf{p}= \left( p_x, p_y \right)$, relative to the population's centre, to be
\[ \rho ( \mathbf{p}) = S_{_L }^{} \frac{1}{2 \pi \sigma^2} \exp \left( - \frac{p_x^2 + p_y^2}{2 \sigma^2} \right) \]
$S_L = 1.015$ is a scaling parameter chosen so that the integral over the
population's effective disk, $\mathbf{D}= \left\{ \mathbf{q} \in {Domain} \left( \rho \right) : \left| \mathbf{q} \right| \leqslant 3 \sigma^2 \right\}$, gives
\[ \int_{\mathbf{D}} \rho \left( \mathbf{p} \right) d\mathbf{p}= 1. \]


\subsubsection{Contaminant handling}

Initially a contact value is calculated for the time step. For an individual,
this value is the integral of the contaminant level over its path. Population
contact is calculated in an analogous way over the domain of the population
and it represents the average contact of the members of the population.

The mass of contaminant which is available for uptake, or contact is, for
individuals, taken to be the result of integrating the intensity of the plume
over its path, $\mathbf{P}_t$ to $\mathbf{P}_{t + \delta}$. Namely,
\[ M = \int_{\mathbf{P}_t}^{\mathbf{P}_{t + \delta_{}}} I ( \mathbf{p}) ||\mathbf{p}|| d \mathbf{p}  \]
where our variable $\mathbf{p}$ is a vector with time and location and we
assume that the motion from $\mathbf{P}_t$ to $\mathbf{P}_{t + \delta}$ is
along a straight line segment. We take $\left\| \mathbf{p} \right\|$ to be the speed at which the
individual is moving.

Population's contact occurs across its domain and we calculate the definite
integral
\[ M = \int_{\mathbf{P}_t}^{\mathbf{P}_{t + \delta}} 2 \int_{\mathbf{\Omega}} I ( \mathbf{p + \omega}) \rho (   \mathbf{\omega}) d \mathbf{\omega} d \mathbf{p}^{}  \]
where $\mathbf{\Omega}$ is an area over which we assess the effective area
of the population and $\mathbf{p}+ \omega$ denotes the area
$\mathbf{\Omega}$ translated so that its centroid corresponds to
$\mathbf{p}$. The contact equations are solved using a simple adaptive
quadrature routine. This value corresponds to the most likely mean contact in
the population.

For both models of our organisms, uptake and depuration is modelled by the
ordinary differential equation
\[ d C / d t = u M - \lambda C \]
where $u = 0.02$ is the uptake rate, a decay rate which is approximately
$\lambda =$0.0059. The equation is solved numerically with a fourth order
Runge-Kutta algorithm for the value of $C$ given a contact mass, $M$, and an
initial contaminant value or vector of values for $C$

\subsubsection{Mutating sub-models}

The individual-based representation requires no change to run in a mutating
configuration, but the population-based representation must maintain a list of
contaminant loads which are processed in exactly the same way a scalar might
be processed in one of the simple configurations. In the mutating
configuration, each instance of a model is assessed at the end of its timestep
to determine whether a change in representation is appropriate.

When a population disaggregates into individuals, the set of individuals with
contaminant loads corresponding to the entries in the list are created. Their
locations are normally distributed within the population disk. Any shortfall
in numbers is handled by creating individuals which have no contaminant load
and positioning them in the same fashion. Once the individuals are created,
the population model is allowed to terminate.

An individual joins a population by having its contaminant load added to the
list the population maintains. The first step in the process is to determine
if there is a population close enough to the individual. If not, an empty
population is created. Once a population's contaminant load has been inserted
into the population the individual is allowed to terminate. The population
model itself does not really play a part in this transaction: the ``import''
call is never used directly by the population, rather it is the supervising
scheduler which organises the transfer to and from individuals and
populations.

\section{Results}\label{Results}

The data presented in section \ref{Correspondence} are based on two sets of
simulations representing forty individuals. The first set uses a circular
plume and the second an elliptical plume. These data sets allow a comparison
of run-times, the equivalence (or lack of equivalence) amongst the submodels,
and thet provide data to examine the robustness of the representations to
changes in the configuration of the plume. To ensure that run-time comparisons
are meaningful all of the simulations in the first set of trials were run on
the same computer.

The first set is comprised of forty trials of the homogeneous individual-based
model, corresponding trials of the mutating model, and a single run of the
population-based model. The second set is comprised of eighty trials of the
mutating model and a single run of the population-based model. The data in the
first set of trials establishes the equivalence of the homogeneous
individual-based model and the mutating model. We pool the data from the
mutating and homogeneous individual-based runs from the first set to match the
eighty runs in the second to compare the effect of the plume's configuration.
The results with an elliptical plume were not consistent across the model
representations.

The individual-based representation produces a time series of
contaminant levels for each individual, while the population submodel
produces a ``mean load'' across a group of entities. The mutating
submodel sits between the two, sometimes producing individual time
series and sometimes mean time series for varying parts of the
population. We denote representations by a subscript $r \in \{i, m,
p\}$, so that $C_{r k j} (t)$ is the contaminant load at $t$ in time
series, $C$, associated with individual $j$ in trial $k$ of
representation $r$, $C_{r k} (t)$ is the mean at a time $t$ over all the
groups simulated in the indicated representation and trial, and $C_r (t)$
denotes the mean of $C_{r k} (t)$ across the $k$ trials for the indicated
representation. To compare the dynamics of the system we generate mean
time series for each of the $k$ trials in the individual-based and
mutating sets, $^{} C_{i k} (t)$ and $^{} C_{m k} (t)$. We are careful to
generate the correct mean in the mutating submodel from time steps
which have a mixture of individual trajectories and mean trajectories
from population-based representations. Each of the mean time series,
$C_{r k} (t)$, corresponds to the mean contaminant load of the
population, $C_p (t)$, produced by the population submodel; averaging
them, that is constructing
\[ C_r (t) = \frac{1}{k} \sum^k_{j = 1} C_{r j} (t), \]
where $r$ is one of `$i$' or `$m$', is equivalent to running many
stochastic trials and averaging to fit the population submodel. Using
$^{} C_{i k} (t)$, $^{} C_{m k} (t)$ and $^{} C_p (t)$ we find the
maximum value attained for each representation, $\hat{C}_r$. We are
also interested in the mean value across time of each representation,
\[ {\bar{C}}_r = \frac{1}{T} \sum_{t \in T} C_r (t) \]


\subsection{Contaminant load correspondence between
representations}\label{Correspondence}



Both sets, $\bar{C}_r$ and $\hat{C}_r$, are presented in Table
\ref{MaximaMeans}.

\begin{table}[h]
\begin{center}
  \caption{Maxima and Means\label{MaximaMeans}}
  \begin{tabular}{ccc}
\hline  &  &   \cr
    ${Series}_r$ & $\hat{C}_r$ & $\bar{C}_r$  \cr
\hline  &  &   \cr
    $C_i$ & $0.1787$ & $0.0390$ \cr
    $C_m$ & $0.1821$ & $0.0392$ \cr
    $C_p$ & $0.1387$ & $0.0350$  \cr
\hline  &  & 
  \end{tabular}
\end{center}
  
  
\end{table}

These data suggest that the mutating representation is consistent with the
homogeneous individual-based representation. The population-based
representation seems to present markedly different mean and maximum values.



\subsection{Contaminant load variability}\label{LoadVar}

We calculated measures of variability in the time series using the aggregated
time series $^{} C_{i k} (t)$ and $^{} C_{m k} (t)$ and their respective means
across the $k$ trials, $C_i (t)$ and $C_m (t)$. We will take $T$ to be the total
number of time steps taken, and we take
\[ \hat{\sigma}_{a b} = \max_{t \in [1, T]} \left[ \frac{1}{k} \sum_{j = 1}^k (C_{a k} (t) - C_b (t))^2 \right]^{1 / 2} \]
and
\[ {\bar{\sigma}}_{a b} = \left[ \frac{1}{T} \sum_{t = 1}^T \left[ \frac{1}{k} \sum_{j = 1}^k (C_{a k} (t) - C_b (t))^2 \right] \right]^{1 / 2}, \]
to be the maximum root mean square error and the average root mean square
error. Clearly we can write $\bar{\sigma}_{r r}$ as $\bar{\sigma}_r$ without
introducing ambiguity, and similarly for $\hat{\sigma}_r$. The values for
these measure of variability are presented in Table \ref{LoadVarTbl}.

\begin{table}[h]
\begin{center}
  \caption{Deviations amongst the model runs with respect to a given   mean\label{LoadVarTbl}}
  \begin{tabular}{cccc}
\hline  &  &  &   \cr
    r.m.s.e. & $r = i$ & $r = m$ & $r = p$  \cr
\hline  &  &  &   \cr
    $\widehat{\sigma_{}}_{i r}$ & $0.0083$ & $0.0084$ & 0.0534 \cr
    $\bar{\sigma}_{i r}$ & 0.0024 & $0.0024$ & $0.0096$ \cr
    $\widehat{\sigma_{}}_{m r}$ & $0.0090$ & $0.0090$ & 0.0538 \cr
    $\bar{\sigma}_{m r}$ & 0.0024 & $0.0024$ & $0.0096$  \cr
\hline  &  &  & 
  \end{tabular}{\hspace{0pt}}{\hfill}
\end{center}
\end{table}

The data here indicate that the variability about the mean is consistent in
the two representations which use simulated individuals to estimate contact
and uptake. This is what we would expect since the mechanisms of uptake and
contact are the same. In contrast, the population's values suggest that the
contact and uptake are quite different, and that this model does not perform
in quite the same way.

\subsection{Sensitivity to the shape of the plume}

We will use the same notation as Section \ref{LoadVar} for the data derived
from the circular plumes, while we will add a prime symbol to the data derived
from the elliptical plumes. Thus, the mean value time series for the mutating
submodel with elliptical plumes would be denoted $C'_m$ and the mean value of
that time series is $\bar{C}'$.

There is a good correspondence between the means and deviations associated
with the mutating model in the circular and elliptical plume scenarios, but
there is much poorer correspondence in the population based results in the two
scenarios. The data for the circular plume and for the elliptical plume are
presented in Tables \ref{Symplume} and \ref{Asymplume} respectively.

\begin{table}[h]
\begin{center}
  \caption{Circular plume results\label{Symplume}}
  \begin{tabular}{ccccccc}
\hline  &  &  &  &  &  &   \cr
    ${Series}_r$ & $\hat{C}_r$ & $\bar{C}_r$ &  & StdDev & $r = m$ & $r =     p$  \cr
\hline  &  &  &  &  &  &   \cr
    $C_m$ & $0.1738$ & $0.0392$ &  & $\widehat{\sigma_{}}_{m r}$ & $0.0088$ &
    0.0535 \cr
    $C_p$ & $0.1387$ & $0.0350$ &  & $\bar{\sigma}_{m r}$ & $0.0024$ &
    $0.0098$  \cr
\hline  &  &  &  &  &  & 
  \end{tabular}
\end{center}
\end{table}

\begin{table}[h]
\begin{center}
  \caption{Elliptical plume results\label{Asymplume}}
  \begin{tabular}{ccccccc}
\hline  &  &  &  &  &  &   \cr
    ${Series}_r$ & $\widehat{C'}_r$ & $\overline{C'}_r$ &  & StdDev & $r     = m$ & $r = p$  \cr
\hline  &  &  &  &  &  &   \cr
    $C'_m$ & $0.1856$ & $0.0394$ &  & $\widehat{\sigma_{}}_{m r}'$ & $0.0087$
    & 0.0616 \cr
    $C'_p$ & $0.1763$ & $0.0445$ &  & $\bar{\sigma}_{m r}'$ & $0.0025$ &
    $0.0092$  \cr
\hline  &  &  &  &  &  & 
  \end{tabular}
\end{center}
\end{table}

The population based model is clearly more sensitive to the shape of the plume
than the mutating model. It seems likely that the major driver of this
difference is that the long axis of the plume (a region where the net contact
will be higher) remains in close proximity to the centroid of population where
the population density is greatest.

\subsection{Run-time}

Each run collected data regarding the amount of time spent in different parts
of the submodel; predictably, most of the effort is in calculating contact and
updating contaminant loads.

The optimisation of supressing the contact calculations when a population is
outside the area of potential contact seemed to make very little difference to
the run-time of population submodel (about 3\%). It seems unlikely to make a
great deal of difference to the mutating submodel. In the case of the purely
individual-based submodel, this sort of optimisation is likely to play a much
bigger role; any penalty would be multiplied by the number of animals
simulated.

The population submodel ran for 98.7 cpu seconds. This submodel is
deterministic and the amount of cpu time used is very stable, so only a single
run is considered for comparison. The purely individual-based submodels took
just over a mean time of 4205 cpu seconds with a standard deviation of
approximately 16 seconds and the mean of the mutating submodel's run time was
1157 cpu seconds with a standard deviation of slightly over 11 cpu seconds.

\section{Discussion}

In the example our objective is to produce time-series data associated with
the contaminant load of the group. Our individual-based model is taken as the
best model for capturing the contact that real organisms have with an
intermittent plume, and the population based representation has a
computational efficiency that the individuals lack. The case for swapping in
the example model is reasonably clear: there is a distinct improvement in
run-time with no apparent deterioration in the fidelity of the dynamics. It
seems likely that the na\"{\i}ve population distribution may be introducing a
systematic divergence from what we see as an accurate, but computationally
intense, individual-based model.

The general case is not limited to the polar extremes of switching between
individual-based models and populations. A niche may have many
representations, each of which has a particular set of strengths and
weaknesses. This adaptive approach would present the same scope for
improvement in purely equation-based models, where rules of thumb might be
replaced by first-order approximations, or by complex systems of differential
equations. In a purely individual-based example, the depth of the
representation of the individual might vary from a simple mass and location
through to a level of detail which included the individual's metabolic rates
and breeding characteristics.

\subsection{State spaces}

To make our population-based model compatible with the individual-based model
we have to extend the population's state space and maintain additional
information to preserve the essential parts of the individual representation
that makes it valuable to us. This is basically posing the first of the
enumerated question from section \ref{Intro}. The {\em{significant}}
information which the individual-based representation possesses is embodied in
the contaminant loads amongst the individuals which comprise the group. We
assume that the role of their relative locations about the population's centre
is not important over a large portion of the global state-space and that we
can discard it when we move from individuals to populations.

The union of submodels' state-spaces can generally be decomposed into
{\em{processing sets}} of state-variables. Partitioning the state variables
in this way -- particularly in advance -- makes it easier to analyse and
minimise the boundary effects associated with the transition from one
representation to another. Within a representation, the state variables which
are unique to it form a special subset. The subset can be divided into the
variables which need to be maintained by other representations, which we call
$V_r^{}$, and the variables which do not which we will call $U_r^{}$. In
principle, the variables in $V_r$ might be maintained by a routine which is
common to them all. The variables in $U_r$ are more complex: when some other
representation is mutating to representation $r$, the values assigned to the
variables in $U_r$ should reflect the state implied by the state of the old
representation.

In the example model, an individual's relative location is a member of this
set. Variables which are maintained and used by more than one representation
are the third major group. This group can be divided into the set which is
used consistently across the submodels ($W_r$), and the group of variables
which have different dynamics in the various representations ($X_r$). In our
example case, the contaminant load level of an individual would belong to the
set $V_{{ind}}$. Its location and velocity would be in $U_{{ind}}$,
the current time for both individuals and populations belongs to $W_r$, and a
list of contaminant loads for populations belongs to $V_{{pop}}$.



\subsection{Heuristics}

The example model has very simple dynamics: the plumes are always in the same
place, the migration is very predictable, and the spatial domain an individual
may explore is well contained. Implementing a heuristic for the model which
efficiently decides when to move from one representation to another is very
straightforward: {\em{If we are close enough that an individual might
encounter the plume if the plume were at its maximum, switch a population to a
group of individuals. Conversely, if there is no chance that an individual
heading straight toward the plume (backwards) will encounter it, move the
individual to a ``close enough'' population, or create a new population to
accomodate the individual.}} The model was constructed so that any number of
populations could be run, and the heuristic was framed so that there were no
assumptions about the number of population agents and the size of the groups
they represented.

In this model, the decision process was shared between the representations
themselves and the controlling scheduler.\label{Heuristics} The
representations reported their ``robustness'' to the scheduler which would
then decide how to act on the advice, either triggering a change in
representation or not.

The goal is to have a complex ensemble of niches which will change
representations under the aegis of the scheduler to optimise the global
outcome. For this more general approach additional information is needed: the
scheduler would incorporate information about what properties each of the
current representations required from other niches in order to decide what the
mix of submodels filling the niches ought to be.

\subsection{Transitions}

The transition from individuals to population and population to individuals
involves the loss and reconstruction of fine-scale position data, which may be
a source of error. In our example, we assume that we can reconstruct a
plausible position for each individual from the population's distribution
function because we know the typical distribution of individuals and there is
no behavioural change associated with contaminant load. A contaminant that
made an organism sluggish would skew the distributions of both the population
as a whole and the distribution of intoxicated organisms within the
population. In the example model, individuals were randomly located in this
way with enough time to randomise their velocities and blur any artifacts
resulting from the selection of their locations. This corresponds to the
perception that the velocities and relative locations of the individuals are
comparatively unimportant except as they related to the distribution of the
population. When values of state variables are generated in the process of
changing to another representation, they need to conform to the distributions
of the representation they are leaving. If for some strange reason (like
behavioural change) the distribution of individuals, for example, does
{\em{not}} conform to the distribution associated with a coherent
population, then additional steps need to be taken accomodate this when
changing to a population-based representation.

In section \ref{Heuristics}, transitions between representations in the
example model are mediated by the scheduler. Decisions to change
representation must be based, in part, on whether the transition will increase
or decrease the efficacy of the suite of representations as a whole. If the
example model were more than a pedagogic tool, it would have been useful to
assess the mean error introduced in the transition from population to
individual and individual to population. Our simulation was aimed at producing
contaminant load results, but in this context our aim would be to track the
mean position, variance and extrema of the distribution of individuals
relative to the population. To do this we would perform a comparison similar
to that of section \ref{Results} but using positional data rather than
contaminant load. The results would indicate if there might be significant
transition effects associated with the change in representation. This sort of
testing should ideally be performed at a number of scales (temporal or
spatial, for example) since the knowledge of how long it takes for the
transition boundary effects to settle (if they do) should feed into the
high-level managing scheduler. In a sophisticated system, a representation
might be spun up in advance so that the boundary effects have settled before
it takes over from a less efficient representation.

\subsection{Errors}

Estimating error and confidence is extremely hard in complex models. Not only
are the abstract processes deeply connected, but there may be hundreds of
thousands of lines of code{\footnote{Ningaloo-InVitro is currently more than
233000 lines of C++, NWS-InVitro is slightly more than 118000 lines of C++ and
Atlantis is more than 145000.}} which may introduce error of their own.
Confronted with the code of a large-scale marine ecosystem model, one might
turn around and contemplate joining a monastery rather than try and track the
error propagation through the system. When we look at making an aggregate
model out of niches, we can make the set of each of the representations which
fill the niche simpler than some chimera which tries to take the best bits of
each of the candidate representations. With well isolated transition
mechanisms, we side-step nests of conditional code-paths and can contain the
potential sources of error we must analyse. Since transitions can be recorded
(like other useful data), we can generate an indication of the likely level of
confidence based on our understanding of the representations used in a
simulation.

\section{Conclusion}

Interesting and unanticipated results have come from this experiment. The
discrepancy between the data concerning elliptical and circular plumes
suggests that, at least in contaminant work, we need to pay closer attention
to the movement dynamics of individuals and the density functions of
populations. More predictably, the run-times show that mutating configurations
provide a reasonable means of increasing computational speed without
sacrificing fidelity in appropriate situations. The simple example
demonstrated that a model which changes the representation of the system
according to its location in its state space could provide much better
computational efficiency than a model with a constant representation with no
loss of accuracy.

Increasing population and resource use often reduce our environment's
resilience and there is a growing need to model larger, more complex parts of
the system we live in. Techniques for this have been iteratively moving toward
a more systematic approach: many models will optimise their run-time and
accuracy by suppressing unnecessary calculation, models will split their
timesteps according to what they are simulating, or perhaps even adaptively
set an appropriate timestep or spatial scale.

This paper proposes that actually changing the representations to suit the
different regions of the state space of the model could provide a better
balance between computational efficiency and error.

In our experience of large scale marine ecosystem modelling, the size of the
system considered is growing much faster than computational capacity. Even for
small systems the possibility of adjusting the representation of submodels to
optimise the accuracy of the model as a whole has great appeal. Mutating
models may provide an effective means of concentrating the use of
computational capacity where it is most needed.



The authors would like to thank the three reviewers whose advice and
suggestions have made this paper much clearer and to the point. Their care and
insight are deeply appreciated.



%% \bibliography{biblio}
%% \bibliographystyle{elsarticle-harv}
%% \biboptions{}
%% \end{document}
